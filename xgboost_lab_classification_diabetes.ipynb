{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpTlOzfClRUc"
      },
      "source": [
        "## XGBoost for classication of diabetes onset prediction data\n",
        "Adapted from https://www.kaggle.com/code/soheiltehranipour/xgboost-tutorial-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OMgtE60Q6K_Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XzUJcR1m7DwE"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0              6      148             72             35        0  33.6   \n",
              "1              1       85             66             29        0  26.6   \n",
              "2              8      183             64              0        0  23.3   \n",
              "3              1       89             66             23       94  28.1   \n",
              "4              0      137             40             35      168  43.1   \n",
              "..           ...      ...            ...            ...      ...   ...   \n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                       0.627   50        1  \n",
              "1                       0.351   31        0  \n",
              "2                       0.672   32        1  \n",
              "3                       0.167   21        0  \n",
              "4                       2.288   33        1  \n",
              "..                        ...  ...      ...  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  \n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load data\n",
        "df = pd.read_csv('datasets_228_482_diabetes.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Sg4RoWrBjoqD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkFElEQVR4nO3dfWyV9f3/8dehPT2ltWXcaE8rlYEr3hWcK6NS5xcmbQkKzJAFM4zBBZMalNEVxmBs8zBdu7EIaFEWDQMmshpvcCY/ZC3ZLGDnBhUybow6ZWhjawNWWmg9Pbaf3x+mRw8F7CnnXOdz2ucjIfmeq59z9XO9Kd/z3HVa6zLGGAEAAFhkSKw3AAAAcC4CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1EmO9gf7o7u7WRx99pLS0NLlcrlhvBwAA9IExRm1tbcrKytKQIRe/RxKXgfLRRx8pOzs71tsAAAD98OGHH2r06NEXXROXgZKWlibpiwtMT0+P6LkDgYCqq6tVXFwst9sd0XPjS8zZGczZGczZOczaGdGac2trq7Kzs4Ov4xcTl4HS87ZOenp6VAIlJSVF6enpfPFHEXN2BnN2BnN2DrN2RrTn3Jdvz+CbZAEAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGCdsALF5/PJ5XKF/PF6vcGPG2Pk8/mUlZWloUOHatq0aTp69GjIOfx+vxYvXqxRo0YpNTVVc+bMUUNDQ2SuBgAADAhh30G54YYb1NjYGPxz+PDh4MfWrFmjtWvXasOGDdq/f7+8Xq+KiorU1tYWXFNaWqodO3aoqqpK+/bt05kzZzRr1ix1dXVF5ooAAEDcC/uXBSYmJobcNelhjNH69eu1atUqzZ07V5K0detWZWRkaPv27SopKdHp06e1adMmPfPMMyosLJQkbdu2TdnZ2dq9e7dmzJhxiZcDAAAGgrAD5d1331VWVpY8Ho/y8/NVXl6ucePG6fjx42pqalJxcXFwrcfj0dSpU1VXV6eSkhLV19crEAiErMnKylJubq7q6uouGCh+v19+vz/4uLW1VdIXv20xEAiEewkX1XO+SJ8XoZizM5izM5izc5i1M6I153DOF1ag5Ofn689//rPGjx+vjz/+WI888ogKCgp09OhRNTU1SZIyMjJCnpORkaETJ05IkpqampSUlKThw4f3WtPz/POpqKjQ6tWrex2vrq5WSkpKOJfQZzU1NVE5L0IxZ2cwZ2cwZ+cwa2dEes7t7e19XhtWoMycOTP4f0+YMEFTpkzR1Vdfra1bt+rmm2+WJLlcrpDnGGN6HTvX161ZuXKlysrKgo9bW1uVnZ2t4uJipaenh3MJXysQCKimpka/OjBE/u6L79smR3zx9fZYz5yLiorkdrtjvZ0Bizk7gzk7h1k7I1pz7nkHpC/Cfovnq1JTUzVhwgS9++67uvPOOyV9cZckMzMzuKa5uTl4V8Xr9aqzs1MtLS0hd1Gam5tVUFBwwc/j8Xjk8Xh6HXe73VH7AvV3u+Tvip9Aidd/qNH8O8SXmLMzmLNzmLUzIj3ncM51Sf8dFL/fr7feekuZmZkaO3asvF5vyO2gzs5O1dbWBuMjLy9Pbrc7ZE1jY6OOHDly0UABAACDS1h3UJYtW6bZs2frqquuUnNzsx555BG1trZqwYIFcrlcKi0tVXl5uXJycpSTk6Py8nKlpKRo/vz5kqRhw4Zp4cKFWrp0qUaOHKkRI0Zo2bJlmjBhQvCnegAAAMIKlIaGBv3oRz/SyZMndfnll+vmm2/WG2+8oTFjxkiSli9fro6ODi1atEgtLS3Kz89XdXW10tLSgudYt26dEhMTNW/ePHV0dGj69OnasmWLEhISIntlAAAgboUVKFVVVRf9uMvlks/nk8/nu+Ca5ORkVVZWqrKyMpxPDQAABhF+Fw8AALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6lxQoFRUVcrlcKi0tDR4zxsjn8ykrK0tDhw7VtGnTdPTo0ZDn+f1+LV68WKNGjVJqaqrmzJmjhoaGS9kKAAAYQPodKPv379dTTz2liRMnhhxfs2aN1q5dqw0bNmj//v3yer0qKipSW1tbcE1paal27Nihqqoq7du3T2fOnNGsWbPU1dXV/ysBAAADRr8C5cyZM7r77rv19NNPa/jw4cHjxhitX79eq1at0ty5c5Wbm6utW7eqvb1d27dvlySdPn1amzZt0qOPPqrCwkLddNNN2rZtmw4fPqzdu3dH5qoAAEBcS+zPkx544AHdcccdKiws1COPPBI8fvz4cTU1Nam4uDh4zOPxaOrUqaqrq1NJSYnq6+sVCARC1mRlZSk3N1d1dXWaMWNGr8/n9/vl9/uDj1tbWyVJgUBAgUCgP5dwQT3n8wwxET1vtEV6DtHWs99423e8Yc7OYM7OYdbOiNacwzlf2IFSVVWlN998U/v37+/1saamJklSRkZGyPGMjAydOHEiuCYpKSnkzkvPmp7nn6uiokKrV6/udby6ulopKSnhXkKfPDypOyrnjZadO3fGegv9UlNTE+stDArM2RnM2TnM2hmRnnN7e3uf14YVKB9++KGWLFmi6upqJScnX3Cdy+UKeWyM6XXsXBdbs3LlSpWVlQUft7a2Kjs7W8XFxUpPTw/jCr5eIBBQTU2NfnVgiPzdF9+zTY74et95slnPnIuKiuR2u2O9nQGLOTuDOTuHWTsjWnPueQekL8IKlPr6ejU3NysvLy94rKurS3v27NGGDRv09ttvS/riLklmZmZwTXNzc/CuitfrVWdnp1paWkLuojQ3N6ugoOC8n9fj8cjj8fQ67na7o/YF6u92yd8VP4ESr/9Qo/l3iC8xZ2cwZ+cwa2dEes7hnCusb5KdPn26Dh8+rEOHDgX/TJo0SXfffbcOHTqkcePGyev1htwS6uzsVG1tbTA+8vLy5Ha7Q9Y0NjbqyJEjFwwUAAAwuIR1ByUtLU25ubkhx1JTUzVy5Mjg8dLSUpWXlysnJ0c5OTkqLy9XSkqK5s+fL0kaNmyYFi5cqKVLl2rkyJEaMWKEli1bpgkTJqiwsDBClwUAAOJZv36K52KWL1+ujo4OLVq0SC0tLcrPz1d1dbXS0tKCa9atW6fExETNmzdPHR0dmj59urZs2aKEhIRIbwcAAMShSw6U1157LeSxy+WSz+eTz+e74HOSk5NVWVmpysrKS/30AABgAOJ38QAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALBOWIGyceNGTZw4Uenp6UpPT9eUKVP06quvBj9ujJHP51NWVpaGDh2qadOm6ejRoyHn8Pv9Wrx4sUaNGqXU1FTNmTNHDQ0NkbkaAAAwIIQVKKNHj9bvfvc7HThwQAcOHNBtt92mH/zgB8EIWbNmjdauXasNGzZo//798nq9KioqUltbW/AcpaWl2rFjh6qqqrRv3z6dOXNGs2bNUldXV2SvDAAAxK2wAmX27Nm6/fbbNX78eI0fP16//e1vddlll+mNN96QMUbr16/XqlWrNHfuXOXm5mrr1q1qb2/X9u3bJUmnT5/Wpk2b9Oijj6qwsFA33XSTtm3bpsOHD2v37t1RuUAAABB/Evv7xK6uLj3//PM6e/aspkyZouPHj6upqUnFxcXBNR6PR1OnTlVdXZ1KSkpUX1+vQCAQsiYrK0u5ubmqq6vTjBkzzvu5/H6//H5/8HFra6skKRAIKBAI9PcSzqvnfJ4hJqLnjbZIzyHaevYbb/uON8zZGczZOczaGdGaczjnCztQDh8+rClTpuizzz7TZZddph07duj6669XXV2dJCkjIyNkfUZGhk6cOCFJampqUlJSkoYPH95rTVNT0wU/Z0VFhVavXt3reHV1tVJSUsK9hD55eFJ3VM4bLTt37oz1FvqlpqYm1lsYFJizM5izc5i1MyI95/b29j6vDTtQrrnmGh06dEiffvqpXnzxRS1YsEC1tbXBj7tcrpD1xphex871dWtWrlypsrKy4OPW1lZlZ2eruLhY6enp4V7CRQUCAdXU1OhXB4bI333xfdvkiO/8d59s1TPnoqIiud3uWG9nwGLOzmDOzmHWzojWnHveAemLsAMlKSlJ3/rWtyRJkyZN0v79+/XYY4/p5z//uaQv7pJkZmYG1zc3Nwfvqni9XnV2dqqlpSXkLkpzc7MKCgou+Dk9Ho88Hk+v4263O2pfoP5ul/xd8RMo8foPNZp/h/gSc3YGc3YOs3ZGpOcczrku+b+DYoyR3+/X2LFj5fV6Q24HdXZ2qra2NhgfeXl5crvdIWsaGxt15MiRiwYKAAAYXMK6g/KLX/xCM2fOVHZ2ttra2lRVVaXXXntNu3btksvlUmlpqcrLy5WTk6OcnByVl5crJSVF8+fPlyQNGzZMCxcu1NKlSzVy5EiNGDFCy5Yt04QJE1RYWBiVCwQAAPEnrED5+OOPdc8996ixsVHDhg3TxIkTtWvXLhUVFUmSli9fro6ODi1atEgtLS3Kz89XdXW10tLSgudYt26dEhMTNW/ePHV0dGj69OnasmWLEhISIntlAAAgboUVKJs2bbrox10ul3w+n3w+3wXXJCcnq7KyUpWVleF8agAAMIjwu3gAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANZJjPUGAAAY6L654v/Fegth8SQYrZkc2z1wBwUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1gkrUCoqKvTd735XaWlpuuKKK3TnnXfq7bffDlljjJHP51NWVpaGDh2qadOm6ejRoyFr/H6/Fi9erFGjRik1NVVz5sxRQ0PDpV8NAAAYEMIKlNraWj3wwAN64403VFNTo88//1zFxcU6e/ZscM2aNWu0du1abdiwQfv375fX61VRUZHa2tqCa0pLS7Vjxw5VVVVp3759OnPmjGbNmqWurq7IXRkAAIhbieEs3rVrV8jjzZs364orrlB9fb3+7//+T8YYrV+/XqtWrdLcuXMlSVu3blVGRoa2b9+ukpISnT59Wps2bdIzzzyjwsJCSdK2bduUnZ2t3bt3a8aMGRG6NAAAEK/CCpRznT59WpI0YsQISdLx48fV1NSk4uLi4BqPx6OpU6eqrq5OJSUlqq+vVyAQCFmTlZWl3Nxc1dXVnTdQ/H6//H5/8HFra6skKRAIKBAIXMol9NJzPs8QE9HzRluk5xBtPfuNt33HG+bsDObsnHidtSchvl5Tel4Do/Ua2xf9DhRjjMrKyvS9731Pubm5kqSmpiZJUkZGRsjajIwMnThxIrgmKSlJw4cP77Wm5/nnqqio0OrVq3sdr66uVkpKSn8v4aIentQdlfNGy86dO2O9hX6pqamJ9RYGBebsDObsnHib9ZrJsd5B/0R6zu3t7X1e2+9AefDBB/Wf//xH+/bt6/Uxl8sV8tgY0+vYuS62ZuXKlSorKws+bm1tVXZ2toqLi5Went6P3V9YIBBQTU2NfnVgiPzdF9+zTY744uutsZ45FxUVye12x3o7AxZzdgZzdk68zjrX97dYbyEsniFGD0/qjvice94B6Yt+BcrixYv1yiuvaM+ePRo9enTwuNfrlfTFXZLMzMzg8ebm5uBdFa/Xq87OTrW0tITcRWlublZBQcF5P5/H45HH4+l13O12R+0L1N/tkr8rfgIlnv6hflU0/w7xJebsDObsnHibdTy9nnxVpOcczrnC+ikeY4wefPBBvfTSS/r73/+usWPHhnx87Nix8nq9IbeEOjs7VVtbG4yPvLw8ud3ukDWNjY06cuTIBQMFAAAMLmHdQXnggQe0fft2/fWvf1VaWlrwe0aGDRumoUOHyuVyqbS0VOXl5crJyVFOTo7Ky8uVkpKi+fPnB9cuXLhQS5cu1ciRIzVixAgtW7ZMEyZMCP5UDwAAGNzCCpSNGzdKkqZNmxZyfPPmzbr33nslScuXL1dHR4cWLVqklpYW5efnq7q6WmlpacH169atU2JioubNm6eOjg5Nnz5dW7ZsUUJCwqVdDQAAGBDCChRjvv7HpFwul3w+n3w+3wXXJCcnq7KyUpWVleF8egAAMEjwu3gAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWCTtQ9uzZo9mzZysrK0sul0svv/xyyMeNMfL5fMrKytLQoUM1bdo0HT16NGSN3+/X4sWLNWrUKKWmpmrOnDlqaGi4pAsBAAADR9iBcvbsWd14443asGHDeT++Zs0arV27Vhs2bND+/fvl9XpVVFSktra24JrS0lLt2LFDVVVV2rdvn86cOaNZs2apq6ur/1cCAAAGjMRwnzBz5kzNnDnzvB8zxmj9+vVatWqV5s6dK0naunWrMjIytH37dpWUlOj06dPatGmTnnnmGRUWFkqStm3bpuzsbO3evVszZsy4hMsBAAADQdiBcjHHjx9XU1OTiouLg8c8Ho+mTp2quro6lZSUqL6+XoFAIGRNVlaWcnNzVVdXd95A8fv98vv9wcetra2SpEAgoEAgEMlLCJ7PM8RE9LzRFuk5RFvPfuNt3/GGOTuDOTsnXmftSYiv15Se18Bovcb2RUQDpampSZKUkZERcjwjI0MnTpwIrklKStLw4cN7rel5/rkqKiq0evXqXserq6uVkpISia338vCk7qicN1p27twZ6y30S01NTay3MCgwZ2cwZ+fE26zXTI71Dvon0nNub2/v89qIBkoPl8sV8tgY0+vYuS62ZuXKlSorKws+bm1tVXZ2toqLi5Wenn7pG/6KQCCgmpoa/erAEPm7L75nmxzxxddbYz1zLioqktvtjvV2Bizm7Azm7Jx4nXWu72+x3kJYPEOMHp7UHfE597wD0hcRDRSv1yvpi7skmZmZwePNzc3Buyper1ednZ1qaWkJuYvS3NysgoKC857X4/HI4/H0Ou52u6P2BervdsnfFT+BEk//UL8qmn+H+BJzdgZzdk68zTqeXk++KtJzDudcEf3voIwdO1ZerzfkllBnZ6dqa2uD8ZGXlye32x2yprGxUUeOHLlgoAAAgMEl7DsoZ86c0X//+9/g4+PHj+vQoUMaMWKErrrqKpWWlqq8vFw5OTnKyclReXm5UlJSNH/+fEnSsGHDtHDhQi1dulQjR47UiBEjtGzZMk2YMCH4Uz0AAGBwCztQDhw4oO9///vBxz3fG7JgwQJt2bJFy5cvV0dHhxYtWqSWlhbl5+erurpaaWlpweesW7dOiYmJmjdvnjo6OjR9+nRt2bJFCQkJEbgkAAAQ78IOlGnTpsmYC/+4lMvlks/nk8/nu+Ca5ORkVVZWqrKyMtxPDwAABgF+Fw8AALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrxDRQnnzySY0dO1bJycnKy8vT3r17Y7kdAABgiZgFynPPPafS0lKtWrVKBw8e1K233qqZM2fqgw8+iNWWAACAJWIWKGvXrtXChQt133336brrrtP69euVnZ2tjRs3xmpLAADAEomx+KSdnZ2qr6/XihUrQo4XFxerrq6u13q/3y+/3x98fPr0aUnSJ598okAgENG9BQIBtbe3KzEwRF3droieO5pOnToV6y2EpWfOp06dktvtjvV2Bizm7Azm7Jx4nXXi52djvYWwJHYbtbd3R3zObW1tkiRjzNfvIWKfNQwnT55UV1eXMjIyQo5nZGSoqamp1/qKigqtXr261/GxY8dGbY/xZtSjsd4BAGAgmR/Fc7e1tWnYsGEXXROTQOnhcoXeoTDG9DomSStXrlRZWVnwcXd3tz755BONHDnyvOsvRWtrq7Kzs/Xhhx8qPT09oufGl5izM5izM5izc5i1M6I1Z2OM2tralJWV9bVrYxIoo0aNUkJCQq+7Jc3Nzb3uqkiSx+ORx+MJOfaNb3wjmltUeno6X/wOYM7OYM7OYM7OYdbOiMacv+7OSY+YfJNsUlKS8vLyVFNTE3K8pqZGBQUFsdgSAACwSMze4ikrK9M999yjSZMmacqUKXrqqaf0wQcf6P7774/VlgAAgCViFih33XWXTp06pd/85jdqbGxUbm6udu7cqTFjxsRqS5K+eDvpoYce6vWWEiKLOTuDOTuDOTuHWTvDhjm7TF9+1gcAAMBB/C4eAABgHQIFAABYh0ABAADWIVAAAIB1BmWgPPnkkxo7dqySk5OVl5envXv3XnR9bW2t8vLylJycrHHjxumPf/yjQzuNb+HM+aWXXlJRUZEuv/xypaena8qUKfrb3/7m4G7jV7hfzz1ef/11JSYm6tvf/nZ0NzhAhDtnv9+vVatWacyYMfJ4PLr66qv1pz/9yaHdxq9w5/zss8/qxhtvVEpKijIzM/XjH/847n43mdP27Nmj2bNnKysrSy6XSy+//PLXPicmr4NmkKmqqjJut9s8/fTT5tixY2bJkiUmNTXVnDhx4rzr33//fZOSkmKWLFlijh07Zp5++mnjdrvNCy+84PDO40u4c16yZIn5/e9/b/7973+bd955x6xcudK43W7z5ptvOrzz+BLunHt8+umnZty4caa4uNjceOONzmw2jvVnznPmzDH5+fmmpqbGHD9+3PzrX/8yr7/+uoO7jj/hznnv3r1myJAh5rHHHjPvv/++2bt3r7nhhhvMnXfe6fDO48vOnTvNqlWrzIsvvmgkmR07dlx0faxeBwddoEyePNncf//9IceuvfZas2LFivOuX758ubn22mtDjpWUlJibb745anscCMKd8/lcf/31ZvXq1ZHe2oDS3znfdddd5pe//KV56KGHCJQ+CHfOr776qhk2bJg5deqUE9sbMMKd8x/+8Aczbty4kGOPP/64GT16dNT2OND0JVBi9To4qN7i6ezsVH19vYqLi0OOFxcXq66u7rzP+ec//9lr/YwZM3TgwAEFAoGo7TWe9WfO5+ru7lZbW5tGjBgRjS0OCP2d8+bNm/Xee+/poYceivYWB4T+zPmVV17RpEmTtGbNGl155ZUaP368li1bpo6ODie2HJf6M+eCggI1NDRo586dMsbo448/1gsvvKA77rjDiS0PGrF6HYzpbzN22smTJ9XV1dXrFxJmZGT0+sWFPZqams67/vPPP9fJkyeVmZkZtf3Gq/7M+VyPPvqozp49q3nz5kVjiwNCf+b87rvvasWKFdq7d68SEwfVP/9+68+c33//fe3bt0/JycnasWOHTp48qUWLFumTTz7h+1AuoD9zLigo0LPPPqu77rpLn332mT7//HPNmTNHlZWVTmx50IjV6+CguoPSw+VyhTw2xvQ69nXrz3ccocKdc4+//OUv8vl8eu6553TFFVdEa3sDRl/n3NXVpfnz52v16tUaP368U9sbMML5eu7u7pbL5dKzzz6ryZMn6/bbb9fatWu1ZcsW7qJ8jXDmfOzYMf3kJz/Rr3/9a9XX12vXrl06fvw4v9MtCmLxOjio/ifUqFGjlJCQ0KvGm5ube9VhD6/Xe971iYmJGjlyZNT2Gs/6M+cezz33nBYuXKjnn39ehYWF0dxm3At3zm1tbTpw4IAOHjyoBx98UNIXL6TGGCUmJqq6ulq33XabI3uPJ/35es7MzNSVV14Z8mvlr7vuOhlj1NDQoJycnKjuOR71Z84VFRW65ZZb9LOf/UySNHHiRKWmpurWW2/VI488wh3uCInV6+CguoOSlJSkvLw81dTUhByvqalRQUHBeZ8zZcqUXuurq6s1adIkud3uqO01nvVnztIXd07uvfdebd++nfeQ+yDcOaenp+vw4cM6dOhQ8M/999+va665RocOHVJ+fr5TW48r/fl6vuWWW/TRRx/pzJkzwWPvvPOOhgwZotGjR0d1v/GqP3Nub2/XkCGhL2MJCQmSvvxf+Lh0MXsdjOq34Fqo58fYNm3aZI4dO2ZKS0tNamqq+d///meMMWbFihXmnnvuCa7v+fGqn/70p+bYsWNm06ZN/JhxH4Q75+3bt5vExETzxBNPmMbGxuCfTz/9NFaXEBfCnfO5+Cmevgl3zm1tbWb06NHmhz/8oTl69Kipra01OTk55r777ovVJcSFcOe8efNmk5iYaJ588knz3nvvmX379plJkyaZyZMnx+oS4kJbW5s5ePCgOXjwoJFk1q5daw4ePBj8cW5bXgcHXaAYY8wTTzxhxowZY5KSksx3vvMdU1tbG/zYggULzNSpU0PWv/baa+amm24ySUlJ5pvf/KbZuHGjwzuOT+HMeerUqUZSrz8LFixwfuNxJtyv568iUPou3Dm/9dZbprCw0AwdOtSMHj3alJWVmfb2dod3HX/CnfPjjz9urr/+ejN06FCTmZlp7r77btPQ0ODwruPLP/7xj4v+/1tbXgddxnAfDAAA2GVQfQ8KAACIDwQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6/x/xdj2I75vydEAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# What is the baseline?  Let's look at a histogram of y (outcome)\n",
        "df[\"Outcome\"].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKGyCKYOjyGU"
      },
      "source": [
        "### We can see that roughly 1/3 of the samples are \"False\", which means that any classifer with accuracy below 66% is useless."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nKf1xwWRi5G5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# split data into X and y\n",
        "# in thie notebook, we use \".values\" which will convert the data\n",
        "# to numpy matrices\n",
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values\n",
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7Ntpx0khi85j"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split # to split the dataset for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ASh91drJjGSS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(614, 8)\n",
            "(614,)\n",
            "(154, 8)\n",
            "(154,)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IyaIA9c2jImw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fit model no training data\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OUUO7zxnkdjB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy of the XGBClassifer Model:  100.0\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_train)\n",
        "accuracy = accuracy_score(y_train, y_pred) * 100\n",
        "print(\"Train accuracy of the XGBClassifer Model: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qhxLsQqxjLaC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy of the XGBClassifer Model:  75.32467532467533\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "print(\"Test accuracy of the XGBClassifer Model: \",accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lURRhb9ktuk"
      },
      "source": [
        "## What can you learn from the last application of XGBClassifer? Is there overfitting?  Try to tune the parameters to get an improved result on the test set.  Note that you don't have that much data, so you can't try too many things because you will get improvements \"by chance\".   What is the best you can get using logistic regression?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best accuracy:  81.81818181818183\n",
            "Best parameters:  {'learning_rate': 0.1, 'max_depth': 5, 'n_estimator': 100, 'subsample': 0.9, 'colsample_bytree': 0.8}\n"
          ]
        }
      ],
      "source": [
        "#Your analysis and code below...  \n",
        "# Define the parameter values to try finding the best combination of parameters to get the best accuracy for the test set\n",
        "learning_rates = [0.1, 0.01, 0.001]\n",
        "max_depths = [3, 5, 7]\n",
        "n_estimators = [100, 500, 1000]\n",
        "subsamples = [0.8, 0.9, 1.0]\n",
        "colsample_bytrees = [0.8, 0.9, 1.0]\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    for max_depth in max_depths:\n",
        "        for n_estimator in n_estimators:\n",
        "            for subsample in subsamples:\n",
        "                for colsample_bytree in colsample_bytrees:\n",
        "                    model = XGBClassifier(learning_rate=learning_rate, n_estimators=n_estimator, max_depth=max_depth, subsample=subsample, colsample_bytree=colsample_bytree)\n",
        "                    model.fit(X_train, y_train)\n",
        "                    y_pred = model.predict(X_test)\n",
        "                    accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "                    if accuracy > best_accuracy:\n",
        "                        best_accuracy = accuracy\n",
        "                        best_params = {\"learning_rate\": learning_rate, \"max_depth\": max_depth, \"n_estimator\": n_estimator, \"subsample\": subsample, \"colsample_bytree\": colsample_bytree}\n",
        "\n",
        "print(\"Best accuracy: \", best_accuracy)\n",
        "print(\"Best parameters: \", best_params)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy of the Logistic Regression Model:  78.50162866449512\n",
            "Test accuracy of the Logistic Regression Model:  78.57142857142857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\STRON\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create a logistic regression model\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Fit the model on the training data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target variable for the training data\n",
        "y_pred_train = logreg.predict(X_train)\n",
        "\n",
        "# Calculate the accuracy of the model on the training data\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train) * 100\n",
        "print(\"Train accuracy of the Logistic Regression Model: \", accuracy_train)\n",
        "\n",
        "# Predict the target variable for the test data\n",
        "y_pred_test = logreg.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model on the test data\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test) * 100\n",
        "print(\"Test accuracy of the Logistic Regression Model: \", accuracy_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
